### 数据去重

数据去重是大数据领域经常碰见的问题，其目的在于清洗掉不可靠数据源产生的脏数据，使得计算结果更加精确。在常见的实时数据去重方案中，
HashSet由于是实现简单使用方便而得到了广泛的应用。此外，也还有一些其它的方案，如：布隆过滤器(Bloom Filter)、RocksDB StateBackend
以及外部存储。下面分别就这三种去重方案进行分析：
  * 布隆过滤器(Bloom Filter)：作为消耗较少效率较高的方案在允许一定的误判的情况下是首选，如果不考虑自己重复造一遍轮子，可以
  使用Guava的BloomFilter来实现去重，使用put()方法放入数据，使用mightContain()判断是否存在，其特点是如果它判断不存在则数
  据一定不存在，如果它判断存在，则数据有一定的概率不存在(这叫做假阳性概率，在构建BloomFilter时可以指定)。
  * RocksDB StateBackend：前面已经提到布隆过滤器存在一定概率的误判，因此在一些要求非常精确的场合并不适用。